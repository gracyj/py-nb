{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: -f\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'dlib' has no attribute 'load_rgb_image'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6ae80b72404c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Processing file: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_rgb_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;31m# The 1 in the second argument indicates that we should upsample the image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# 1 time.  This will make everything bigger and allow us to detect more\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'dlib' has no attribute 'load_rgb_image'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import dlib\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "win = dlib.image_window()\n",
    "for f in sys.argv[1:]:\n",
    "    print(\"Processing file: {}\".format(f))\n",
    "    img = dlib.load_rgb_image(f)\n",
    "    # The 1 in the second argument indicates that we should upsample the image\n",
    "    # 1 time.  This will make everything bigger and allow us to detect more\n",
    "    # faces.\n",
    "    dets = detector(img, 1)\n",
    "    print(\"Number of faces detected: {}\".format(len(dets)))\n",
    "    for i, d in enumerate(dets):\n",
    "        print(\"Detection {}: Left: {} Top: {} Right: {} Bottom: {}\".format(\n",
    "            i, d.left(), d.top(), d.right(), d.bottom()))\n",
    "\n",
    "    win.clear_overlay()\n",
    "    win.set_image(img)\n",
    "    win.add_overlay(dets)\n",
    "    dlib.hit_enter_to_continue()\n",
    "\n",
    "\n",
    "# Finally, if you really want to you can ask the detector to tell you the score\n",
    "# for each detection.  The score is bigger for more confident detections.\n",
    "# The third argument to run is an optional adjustment to the detection threshold,\n",
    "# where a negative value will return more detections and a positive value fewer.\n",
    "# Also, the idx tells you which of the face sub-detectors matched.  This can be\n",
    "# used to broadly identify faces in different orientations.\n",
    "if (len(sys.argv[1:]) > 0):\n",
    "    img = dlib.load_rgb_image(sys.argv[1])\n",
    "    dets, scores, idx = detector.run(img, 1, -1)\n",
    "    for i, d in enumerate(dets):\n",
    "        print(\"Detection {}, score: {}, face_type:{}\".format(\n",
    "            d, scores[i], idx[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call this program like this:\n",
      "   ./face_recognition.py shape_predictor_5_face_landmarks.dat dlib_face_recognition_resnet_model_v1.dat ../examples/faces\n",
      "You can download a trained facial shape predictor and recognition model from:\n",
      "    http://dlib.net/files/shape_predictor_5_face_landmarks.dat.bz2\n",
      "    http://dlib.net/files/dlib_face_recognition_resnet_model_v1.dat.bz2\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ba07ff6c4420>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mpredictor_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mface_rec_model_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mfaces_folder_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# Load all the models we need: a detector to find the faces, a shape predictor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import dlib\n",
    "import glob\n",
    "\n",
    "if len(sys.argv) != 4:\n",
    "    print(\n",
    "        \"Call this program like this:\\n\"\n",
    "        \"   ./face_recognition.py shape_predictor_5_face_landmarks.dat dlib_face_recognition_resnet_model_v1.dat ../examples/faces\\n\"\n",
    "        \"You can download a trained facial shape predictor and recognition model from:\\n\"\n",
    "        \"    http://dlib.net/files/shape_predictor_5_face_landmarks.dat.bz2\\n\"\n",
    "        \"    http://dlib.net/files/dlib_face_recognition_resnet_model_v1.dat.bz2\")\n",
    "    exit()\n",
    "\n",
    "predictor_path = sys.argv[1]\n",
    "face_rec_model_path = sys.argv[2]\n",
    "faces_folder_path = sys.argv[3]\n",
    "\n",
    "# Load all the models we need: a detector to find the faces, a shape predictor\n",
    "# to find face landmarks so we can precisely localize the face, and finally the\n",
    "# face recognition model.\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "sp = dlib.shape_predictor(predictor_path)\n",
    "facerec = dlib.face_recognition_model_v1(face_rec_model_path)\n",
    "\n",
    "win = dlib.image_window()\n",
    "\n",
    "# Now process all the images\n",
    "for f in glob.glob(os.path.join(faces_folder_path, \"*.jpg\")):\n",
    "    print(\"Processing file: {}\".format(f))\n",
    "    img = dlib.load_rgb_image(f)\n",
    "\n",
    "    win.clear_overlay()\n",
    "    win.set_image(img)\n",
    "\n",
    "    # Ask the detector to find the bounding boxes of each face. The 1 in the\n",
    "    # second argument indicates that we should upsample the image 1 time. This\n",
    "    # will make everything bigger and allow us to detect more faces.\n",
    "    dets = detector(img, 1)\n",
    "    print(\"Number of faces detected: {}\".format(len(dets)))\n",
    "\n",
    "    # Now process each face we found.\n",
    "    for k, d in enumerate(dets):\n",
    "        print(\"Detection {}: Left: {} Top: {} Right: {} Bottom: {}\".format(\n",
    "            k, d.left(), d.top(), d.right(), d.bottom()))\n",
    "        # Get the landmarks/parts for the face in box d.\n",
    "        shape = sp(img, d)\n",
    "        # Draw the face landmarks on the screen so we can see what face is currently being processed.\n",
    "        win.clear_overlay()\n",
    "        win.add_overlay(d)\n",
    "        win.add_overlay(shape)\n",
    "\n",
    "        # Compute the 128D vector that describes the face in img identified by\n",
    "        # shape.  In general, if two face descriptor vectors have a Euclidean\n",
    "        # distance between them less than 0.6 then they are from the same\n",
    "        # person, otherwise they are from different people. Here we just print\n",
    "        # the vector to the screen.\n",
    "        face_descriptor = facerec.compute_face_descriptor(img, shape)\n",
    "        print(face_descriptor)\n",
    "        # It should also be noted that you can also call this function like this:\n",
    "        #  face_descriptor = facerec.compute_face_descriptor(img, shape, 100)\n",
    "        # The version of the call without the 100 gets 99.13% accuracy on LFW\n",
    "        # while the version with 100 gets 99.38%.  However, the 100 makes the\n",
    "        # call 100x slower to execute, so choose whatever version you like.  To\n",
    "        # explain a little, the 3rd argument tells the code how many times to\n",
    "        # jitter/resample the image.  When you set it to 100 it executes the\n",
    "        # face descriptor extraction 100 times on slightly modified versions of\n",
    "        # the face and returns the average result.  You could also pick a more\n",
    "        # middle value, such as 10, which is only 10x slower but still gets an\n",
    "        # LFW accuracy of 99.3%.\n",
    "\n",
    "\n",
    "        dlib.hit_enter_to_continue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
