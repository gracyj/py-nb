{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import dlib\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from sys import argv\n",
    "from sys import stdout\n",
    "from sys import exit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x9d in position 571: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-c3da8814a226>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;31m#raw_text = raw_text.lower() <--- removed lower conversion! accidentally left that in form alice in wonder land 0_o\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mchars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mn_chars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mn_vocab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mStreamWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCodec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStreamWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x9d in position 571: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "data_filename = (\"./wonderland.txt\")\n",
    "d=pd.read_table(data_filename,sep=\"\\t\")\n",
    "raw_text = open(\"./wonderland.txt\")\n",
    "if __name__==\"__main__\":\n",
    "\t#ill modularize this eventually\t\n",
    "\tif len(argv) != 3:\n",
    "\t\tprint (\"Usage: %s [data file] [weights filename]\"% (argv[0]))\n",
    "\t\texit(1)\n",
    "\tdata_filename = argv[1]\n",
    "\traw_text = open(\"./wonderland.txt\")\n",
    "\t#raw_text = raw_text.lower() <--- removed lower conversion! accidentally left that in form alice in wonder land 0_o\n",
    "\t\n",
    "\tchars = sorted(list(set(raw_text)))\n",
    "\tn_chars = len(raw_text)\n",
    "\tn_vocab = len(chars)\n",
    "\t\n",
    "\tint_to_char = dict((i,c) for i,c in enumerate(chars))\t\n",
    "\tchar_to_int = dict((c,i) for i,c in enumerate(chars))\n",
    "\t\n",
    "\tprint( \"[*] Total Characters:\", n_chars)\n",
    "\tprint (\"[*] Total Vocab:\", n_vocab)\n",
    "\n",
    "\tseq_length = 100\n",
    "\tdataX = []\n",
    "\tdataY = []\n",
    "\t\n",
    "\tfor i in range(0,n_chars - seq_length, 1):\n",
    "\t\t#selection\n",
    "\t\tseq_in = raw_text[i:i + seq_length]\n",
    "\t\tseq_out = raw_text[i + seq_length]\n",
    "\t\t#select data form, to make this more readable i should encapsulate it in methods\t\n",
    "\t\tdataX.append([char_to_int[char] for char in seq_in])\n",
    "\t\tdataY.append(char_to_int[seq_out])\n",
    "\t\t\t\t\n",
    "\tn_patterns = len(dataX)\n",
    "\tprint( \"[*] Total Patterns:\", n_patterns)\n",
    "\t\n",
    "\tX = numpy.reshape(dataX,(n_patterns,seq_length,1))\n",
    "\tX = X / float(n_vocab)\n",
    "\ty = np_utils.to_categorical(dataY)\t\n",
    "\t#generate using LSTM network\n",
    "\tweights_filename = argv[2]\n",
    "\t\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(128,input_shape=(X.shape[1],X.shape[2]),return_sequences=True))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(LSTM(128))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Dense(y.shape[1],activation='softmax'))\n",
    "\tmodel.load_weights(weights_filename)\n",
    "\n",
    "\n",
    "\tstart = numpy.random.randint(0,len(dataX) - 1)\n",
    "\tpattern = dataX[start]\n",
    "\tseed = ''.join([int_to_char[value] for value in pattern]), \" \"\n",
    "\t#print \"[*] pattern:\",pattern\n",
    "\tprint (\"[*] Seed: \", seed[0],) \n",
    "\t\n",
    "\tfor i in range(1000):\n",
    "\t\tx = numpy.reshape(pattern,(1,len(pattern),1))\n",
    "\t\tx = x / float(n_vocab)\n",
    "\t\tprediction = model.predict(x,verbose=0)\n",
    "\t\tindex = numpy.argmax(prediction)\n",
    "\t\tresult  = int_to_char[index]\n",
    "\t\tstdout.write(result)\n",
    "\t\tpattern.append(index)\n",
    "\t\tpattern = pattern[1:len(pattern)]\t\n",
    "print (\"\\n[*] done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
